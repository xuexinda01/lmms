# CONV=qwen_1_5
# MODEL_NAME=llava_qwen
CONV=llama_3
MODEL_NAME=llava_llama

# egothink
# mmbench
# ok_vqa,vqav2,vizwiz_vqa,mme,pope,chartqa,docvqa,ai2d,seedbench,mmstar,mmmu,cmmmu,ocrbench,textvqa
export HF_ENDPOINT=https://hf-mirror.com
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6 accelerate launch --num_processes=7 \
-m lmms_eval \
    --model llava_onevision \
    --model_args pretrained=/home/vlm/workspace/checkpoints/direct_finetune_Llava-Onevision-baseline-llama3.1,model_name=$MODEL_NAME \
    --tasks  ok_vqa,vqav2,vizwiz_vqa,mme,pope,chartqa,docvqa,ai2d,seedbench,mmstar,mmmu,cmmmu,ocrbench,textvqa\
    --output_path /home/henry/LLaVA-NeXT/scripts/logs/ \
    --batch_size 1 \
    --log_samples \
    --log_samples_suffix llava_onevision \
